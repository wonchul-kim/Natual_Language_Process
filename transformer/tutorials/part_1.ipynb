{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adverse-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-adoption",
   "metadata": {},
   "source": [
    "### 1. Load vocabulary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "infinite-fiber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_model = '../data/kowiki.model'\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vulnerable-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ['내일은 비가 오네요.',\n",
    "              '오늘은 날씨가 좋네요.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bulgarian-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁내', '일은', '▁비', '가', '▁오', '네', '요', '.']\n",
      "[114, 2979, 78, 3496, 64, 3753, 3656, 3487]\n",
      "['▁오늘', '은', '▁날', '씨', '가', '▁좋', '네', '요', '.']\n",
      "[1597, 3501, 691, 3924, 3496, 776, 3753, 3656, 3487]\n"
     ]
    }
   ],
   "source": [
    "vocab_list = []\n",
    "for example in examples:\n",
    "    pieces = vocab.encode_as_pieces(example)\n",
    "    print(pieces)\n",
    "    ids = vocab.encode_as_ids(example)\n",
    "    print(ids)\n",
    "    vocab_list.append(torch.tensor(ids))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wrong-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 114, 2979,   78, 3496,   64, 3753, 3656, 3487,    0],\n",
      "        [1597, 3501,  691, 3924, 3496,  776, 3753, 3656, 3487]])\n",
      "torch.Size([2, 9])\n"
     ]
    }
   ],
   "source": [
    "# 문장마다 길이가 다르기 때문에 생기는 차이는 `pad(0)`으로 채워준다.\n",
    "inputs = torch.nn.utils.rnn.pad_sequence(vocab_list, \\\n",
    "                                 batch_first=True, padding_value=0)\n",
    "\n",
    "print(inputs)\n",
    "print(inputs.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-atlantic",
   "metadata": {},
   "source": [
    "### 2. Embedding\n",
    "\n",
    "모델이 해석할 수 있는 입력값으로 매핑해주는 역할을 한다. 이 때, **Transformer**의 `embedding`은 다음과 같이 두 가지를 합해서 사용한다.\n",
    "\n",
    "* Input Embedding\n",
    "* Positional Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-rebel",
   "metadata": {},
   "source": [
    "#### 2-1. Input embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geological-volume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8007\n",
      "torch.Size([2, 9, 128])\n"
     ]
    }
   ],
   "source": [
    "num_vocabs = len(vocab)\n",
    "print(num_vocabs)\n",
    "dim_hidn = 128 # 데이터를 어느 정도의 길이/차원으로 바꿔줄지를 선택\n",
    "nn_embed = nn.Embedding(num_vocabs, dim_hidn)\n",
    "\n",
    "inputs_embed = nn_embed(inputs)\n",
    "print(inputs_embed.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-exhibit",
   "metadata": {},
   "source": [
    "#### 2-2. Positional embedding\n",
    "\n",
    "- 각 position별 angle 값 구하기.\n",
    "- 구해진 angle 중 짝수 index의 값에 대한 sin 적용\n",
    "- 구해진 angle 중 홀수 index의 값에 대한 cos 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "micro-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(num_seq, dim_hidn):\n",
    "\n",
    "    def cal_angle(pos, idx_hidn):\n",
    "        return pos/np.power(10000, \\\n",
    "                            2*(idx_hidn//2)/dim_hidn)\n",
    "    \n",
    "    def get_pos_angle(pos):\n",
    "        return [cal_angle(pos, idx_hidn) for idx_hidn \\\n",
    "                                            in range(dim_hidn)]\n",
    "    \n",
    "    sinusoid_table = np.array([get_pos_angle(i_seq) for \\\n",
    "                                           i_seq in range(num_seq)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "binary-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_seqs = 64\n",
    "pos_encoding = positional_encoding(num_seqs, dim_hidn)\n",
    "\n",
    "print (pos_encoding.shape)\n",
    "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, dim_hidn))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-cuisine",
   "metadata": {},
   "source": [
    "위의 그래프에서 알 수 있듯이, position마다 주기(depth)가 다르므로 서로 다른 값으로 매핑되는 것을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-dispute",
   "metadata": {},
   "source": [
    "position embedding을 위한 position encoding lookup table이 만들어졌으므로 이를 활용하여 입력값에서의 위치에 맞는 embedding값을 대응하기 위해서 nn.Embedding의 weight로 적용시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "monetary-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 앞서 구한 pos_encoding의 table을 nn.Embedding으로 하여 positional embedding을 하는 함수를 만들어준다.\n",
    "# 이 때, 학습되는 값이 아니므로 `freeze=True`로 한다.\n",
    "pos_encoding = torch.FloatTensor(pos_encoding)\n",
    "nn_pos_embed = nn.Embedding.from_pretrained(pos_encoding, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dried-pipeline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 주어진 입력값의 vocab마다의 순서/위치를 나타내는 vector를 만든다.\n",
    "pos = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(\\\n",
    "                                                          inputs.size(0), inputs.size(1)).contiguous() + 1\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sustained-imperial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 앞서 구한 position에서 입력값의 <pad>에 해당하는 부분은 사용하지 않도록 mask를 만든다.\n",
    "pos_mask = inputs.eq(0) # 0과 같으면 True, 아니면 False\n",
    "pos_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intimate-actor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 114, 2979,   78, 3496,   64, 3753, 3656, 3487,    0],\n",
      "        [1597, 3501,  691, 3924, 3496,  776, 3753, 3656, 3487]])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 0],\n",
      "        [1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "torch.Size([2, 9, 128])\n"
     ]
    }
   ],
   "source": [
    "# 4. mask를 적용한 pos 벡터를 통해서 position embedding을 구한다.\n",
    "pos.masked_fill_(pos_mask, 0) # mask의 True인 위치의 값만 0으로 대체 \n",
    "pos_embed = nn_pos_embed(pos) # position embedding\n",
    "\n",
    "print(inputs)\n",
    "print(pos)\n",
    "print(pos_embed.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reasonable-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_pos_embed = inputs_embed + pos_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-frost",
   "metadata": {},
   "source": [
    "### 3. Scaled dot production attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-carnival",
   "metadata": {},
   "source": [
    "<img src='../imgs/dot_production_attn.png' width=500>\n",
    "\n",
    "위와 같이 입력값은 `Q`, `K`, `V`, `attention mask`로 구성되어 있고, `K`와 `V`는 값은 값이어야 한다. 이 때, `Q, K, V`가 모두 동일하다면 **self-attention**이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "driving-restaurant",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 128])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9, 9])\n",
      "tensor([[[False, False, False, False, False, False, False, False,  True],\n",
      "         [False, False, False, False, False, False, False, False,  True],\n",
      "         [False, False, False, False, False, False, False, False,  True],\n",
      "         [False, False, False, False, False, False, False, False,  True],\n",
      "         [False, False, False, False, False, False, False, False,  True],\n",
      "         [False, False, False, False, False, False, False, False,  True],\n",
      "         [False, False, False, False, False, False, False, False,  True],\n",
      "         [False, False, False, False, False, False, False, False,  True],\n",
      "         [False, False, False, False, False, False, False, False,  True]],\n",
      "\n",
      "        [[False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "# 1. MatMul\n",
    "Q = inputs_pos_embed\n",
    "K= inputs_pos_embed\n",
    "V = inputs_pos_embed\n",
    "# attn_mask의 shape은 Q와 K의 matmul한 이후의 shape와 동일해야한다.\n",
    "attn_mask = inputs.eq(0).unsqueeze(1).expand(Q.size(0), Q.size(1), K.size(1))\n",
    "print(Q.size())\n",
    "print(inputs.size())\n",
    "print(attn_mask.size())\n",
    "print(attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "placed-magnet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 9])\n",
      "tensor([[[239.8143,  82.1622,  60.1543,  48.2025,  74.3388,  64.4771,  68.2597,\n",
      "           43.4250,  91.3062],\n",
      "         [ 82.1622, 222.6051,  68.1487,  83.6456,  53.8603,  85.1838,  87.8367,\n",
      "           33.1051,  89.9340],\n",
      "         [ 60.1543,  68.1487, 208.5611,  48.2173,  62.8902,  37.6314,  38.1449,\n",
      "           50.2315,  89.2248],\n",
      "         [ 48.2025,  83.6456,  48.2173, 166.4888,  58.7092,  71.3033,  64.9827,\n",
      "           26.7374,  56.8726],\n",
      "         [ 74.3388,  53.8603,  62.8902,  58.7092, 188.9280,  33.8017,  74.4620,\n",
      "           22.5769,  70.2024],\n",
      "         [ 64.4771,  85.1838,  37.6314,  71.3033,  33.8017, 204.8648,  70.9715,\n",
      "           23.5115,  34.5963],\n",
      "         [ 68.2597,  87.8367,  38.1449,  64.9827,  74.4619,  70.9715, 170.7333,\n",
      "           30.3466,  61.0817],\n",
      "         [ 43.4250,  33.1051,  50.2315,  26.7374,  22.5769,  23.5115,  30.3466,\n",
      "          146.7108,  30.0690],\n",
      "         [ 91.3062,  89.9340,  89.2248,  56.8726,  70.2024,  34.5963,  61.0817,\n",
      "           30.0690, 208.1362]],\n",
      "\n",
      "        [[183.0825,  67.7698,  71.1628,  38.0529,  39.2326,  43.1446,  35.5870,\n",
      "           42.5066,  25.2712],\n",
      "         [ 67.7698, 227.5634,  87.2672,  58.3580,  42.6979,  37.8659,  39.6617,\n",
      "           59.7816,  21.8569],\n",
      "         [ 71.1628,  87.2672, 200.3778,  69.1264,  70.4118,  57.7484,  38.9785,\n",
      "           62.0803,  44.5404],\n",
      "         [ 38.0529,  58.3580,  69.1264, 213.7493,  52.8727,  47.6116,  43.8610,\n",
      "           27.7499,  23.7907],\n",
      "         [ 39.2326,  42.6979,  70.4118,  52.8727, 173.1906,  77.8878,  73.2760,\n",
      "           62.7877,  23.1746],\n",
      "         [ 43.1446,  37.8659,  57.7484,  47.6116,  77.8878, 177.7603,  51.4388,\n",
      "           56.9257,  26.9445],\n",
      "         [ 35.5870,  39.6617,  38.9785,  43.8610,  73.2760,  51.4388, 208.7655,\n",
      "           72.6296,  24.9235],\n",
      "         [ 42.5066,  59.7816,  62.0803,  27.7499,  62.7877,  56.9257,  72.6296,\n",
      "          171.2538,  30.1545],\n",
      "         [ 25.2712,  21.8569,  44.5404,  23.7907,  23.1746,  26.9445,  24.9235,\n",
      "           30.1545, 144.7227]]], grad_fn=<UnsafeViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "scores = torch.matmul(Q, K.transpose(-1, -2)) # 또는 K.transpose(1, 2)도 동일\n",
    "print(scores.size())\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "northern-mobility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 9])\n",
      "tensor([[[ 3.7471e+00,  1.2838e+00,  9.3991e-01,  7.5316e-01,  1.1615e+00,\n",
      "           1.0075e+00,  1.0666e+00,  6.7852e-01, -1.2500e+08],\n",
      "         [ 1.2838e+00,  3.4782e+00,  1.0648e+00,  1.3070e+00,  8.4157e-01,\n",
      "           1.3310e+00,  1.3724e+00,  5.1727e-01, -1.2500e+08],\n",
      "         [ 9.3991e-01,  1.0648e+00,  3.2588e+00,  7.5340e-01,  9.8266e-01,\n",
      "           5.8799e-01,  5.9601e-01,  7.8487e-01, -1.2500e+08],\n",
      "         [ 7.5316e-01,  1.3070e+00,  7.5340e-01,  2.6014e+00,  9.1733e-01,\n",
      "           1.1141e+00,  1.0154e+00,  4.1777e-01, -1.2500e+08],\n",
      "         [ 1.1615e+00,  8.4157e-01,  9.8266e-01,  9.1733e-01,  2.9520e+00,\n",
      "           5.2815e-01,  1.1635e+00,  3.5276e-01, -1.2500e+08],\n",
      "         [ 1.0075e+00,  1.3310e+00,  5.8799e-01,  1.1141e+00,  5.2815e-01,\n",
      "           3.2010e+00,  1.1089e+00,  3.6737e-01, -1.2500e+08],\n",
      "         [ 1.0666e+00,  1.3724e+00,  5.9601e-01,  1.0154e+00,  1.1635e+00,\n",
      "           1.1089e+00,  2.6677e+00,  4.7417e-01, -1.2500e+08],\n",
      "         [ 6.7852e-01,  5.1727e-01,  7.8487e-01,  4.1777e-01,  3.5276e-01,\n",
      "           3.6737e-01,  4.7417e-01,  2.2924e+00, -1.2500e+08],\n",
      "         [ 1.4267e+00,  1.4052e+00,  1.3941e+00,  8.8863e-01,  1.0969e+00,\n",
      "           5.4057e-01,  9.5440e-01,  4.6983e-01, -1.2500e+08]],\n",
      "\n",
      "        [[ 2.8607e+00,  1.0589e+00,  1.1119e+00,  5.9458e-01,  6.1301e-01,\n",
      "           6.7413e-01,  5.5605e-01,  6.6417e-01,  3.9486e-01],\n",
      "         [ 1.0589e+00,  3.5557e+00,  1.3636e+00,  9.1184e-01,  6.6716e-01,\n",
      "           5.9165e-01,  6.1971e-01,  9.3409e-01,  3.4151e-01],\n",
      "         [ 1.1119e+00,  1.3636e+00,  3.1309e+00,  1.0801e+00,  1.1002e+00,\n",
      "           9.0232e-01,  6.0904e-01,  9.7001e-01,  6.9594e-01],\n",
      "         [ 5.9458e-01,  9.1184e-01,  1.0801e+00,  3.3398e+00,  8.2614e-01,\n",
      "           7.4393e-01,  6.8533e-01,  4.3359e-01,  3.7173e-01],\n",
      "         [ 6.1301e-01,  6.6716e-01,  1.1002e+00,  8.2614e-01,  2.7061e+00,\n",
      "           1.2170e+00,  1.1449e+00,  9.8106e-01,  3.6210e-01],\n",
      "         [ 6.7413e-01,  5.9165e-01,  9.0232e-01,  7.4393e-01,  1.2170e+00,\n",
      "           2.7775e+00,  8.0373e-01,  8.8946e-01,  4.2101e-01],\n",
      "         [ 5.5605e-01,  6.1971e-01,  6.0904e-01,  6.8533e-01,  1.1449e+00,\n",
      "           8.0373e-01,  3.2620e+00,  1.1348e+00,  3.8943e-01],\n",
      "         [ 6.6417e-01,  9.3409e-01,  9.7001e-01,  4.3359e-01,  9.8106e-01,\n",
      "           8.8946e-01,  1.1348e+00,  2.6758e+00,  4.7116e-01],\n",
      "         [ 3.9486e-01,  3.4151e-01,  6.9594e-01,  3.7173e-01,  3.6210e-01,\n",
      "           4.2101e-01,  3.8943e-01,  4.7116e-01,  2.2613e+00]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 2. Scale\n",
    "dim_head = 64\n",
    "scores = scores.mul_(1/dim_head**0.5)\n",
    "print(scores.size())\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-memorial",
   "metadata": {},
   "source": [
    "> dim_head?????????????????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "improved-correction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 9])\n",
      "tensor([[[ 2.9977e+01,  1.0270e+01,  7.5193e+00,  6.0253e+00,  9.2924e+00,\n",
      "           8.0596e+00,  8.5325e+00,  5.4281e+00, -1.0000e+09],\n",
      "         [ 1.0270e+01,  2.7826e+01,  8.5186e+00,  1.0456e+01,  6.7325e+00,\n",
      "           1.0648e+01,  1.0980e+01,  4.1381e+00, -1.0000e+09],\n",
      "         [ 7.5193e+00,  8.5186e+00,  2.6070e+01,  6.0272e+00,  7.8613e+00,\n",
      "           4.7039e+00,  4.7681e+00,  6.2789e+00, -1.0000e+09],\n",
      "         [ 6.0253e+00,  1.0456e+01,  6.0272e+00,  2.0811e+01,  7.3387e+00,\n",
      "           8.9129e+00,  8.1228e+00,  3.3422e+00, -1.0000e+09],\n",
      "         [ 9.2924e+00,  6.7325e+00,  7.8613e+00,  7.3387e+00,  2.3616e+01,\n",
      "           4.2252e+00,  9.3077e+00,  2.8221e+00, -1.0000e+09],\n",
      "         [ 8.0596e+00,  1.0648e+01,  4.7039e+00,  8.9129e+00,  4.2252e+00,\n",
      "           2.5608e+01,  8.8714e+00,  2.9389e+00, -1.0000e+09],\n",
      "         [ 8.5325e+00,  1.0980e+01,  4.7681e+00,  8.1228e+00,  9.3077e+00,\n",
      "           8.8714e+00,  2.1342e+01,  3.7933e+00, -1.0000e+09],\n",
      "         [ 5.4281e+00,  4.1381e+00,  6.2789e+00,  3.3422e+00,  2.8221e+00,\n",
      "           2.9389e+00,  3.7933e+00,  1.8339e+01, -1.0000e+09],\n",
      "         [ 1.1413e+01,  1.1242e+01,  1.1153e+01,  7.1091e+00,  8.7753e+00,\n",
      "           4.3245e+00,  7.6352e+00,  3.7586e+00, -1.0000e+09]],\n",
      "\n",
      "        [[ 2.2885e+01,  8.4712e+00,  8.8953e+00,  4.7566e+00,  4.9041e+00,\n",
      "           5.3931e+00,  4.4484e+00,  5.3133e+00,  3.1589e+00],\n",
      "         [ 8.4712e+00,  2.8445e+01,  1.0908e+01,  7.2948e+00,  5.3372e+00,\n",
      "           4.7332e+00,  4.9577e+00,  7.4727e+00,  2.7321e+00],\n",
      "         [ 8.8953e+00,  1.0908e+01,  2.5047e+01,  8.6408e+00,  8.8015e+00,\n",
      "           7.2185e+00,  4.8723e+00,  7.7600e+00,  5.5675e+00],\n",
      "         [ 4.7566e+00,  7.2948e+00,  8.6408e+00,  2.6719e+01,  6.6091e+00,\n",
      "           5.9514e+00,  5.4826e+00,  3.4687e+00,  2.9738e+00],\n",
      "         [ 4.9041e+00,  5.3372e+00,  8.8015e+00,  6.6091e+00,  2.1649e+01,\n",
      "           9.7360e+00,  9.1595e+00,  7.8485e+00,  2.8968e+00],\n",
      "         [ 5.3931e+00,  4.7332e+00,  7.2185e+00,  5.9514e+00,  9.7360e+00,\n",
      "           2.2220e+01,  6.4299e+00,  7.1157e+00,  3.3681e+00],\n",
      "         [ 4.4484e+00,  4.9577e+00,  4.8723e+00,  5.4826e+00,  9.1595e+00,\n",
      "           6.4299e+00,  2.6096e+01,  9.0787e+00,  3.1154e+00],\n",
      "         [ 5.3133e+00,  7.4727e+00,  7.7600e+00,  3.4687e+00,  7.8485e+00,\n",
      "           7.1157e+00,  9.0787e+00,  2.1407e+01,  3.7693e+00],\n",
      "         [ 3.1589e+00,  2.7321e+00,  5.5675e+00,  2.9738e+00,  2.8968e+00,\n",
      "           3.3681e+00,  3.1154e+00,  3.7693e+00,  1.8090e+01]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 3. Mask opt.\n",
    "# 매우 작은 숫자로 해주어야 softmax를 통해서 확률로 바꿀 때 0이 된다.\n",
    "scores.masked_fill_(attn_mask, -1e9)\n",
    "print(scores.size())\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "inside-aurora",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 9])\n",
      "tensor([[[1.0000e+00, 2.7642e-09, 1.7654e-10, 3.9628e-11, 1.0396e-09,\n",
      "          3.0304e-10, 4.8624e-10, 2.1810e-11, 0.0000e+00],\n",
      "         [2.3758e-08, 1.0000e+00, 4.1215e-09, 2.8598e-08, 6.9086e-10,\n",
      "          3.4661e-08, 4.8290e-08, 5.1600e-11, 0.0000e+00],\n",
      "         [8.7794e-09, 2.3848e-08, 1.0000e+00, 1.9745e-09, 1.2359e-08,\n",
      "          5.2574e-10, 5.6059e-10, 2.5397e-09, 0.0000e+00],\n",
      "         [3.7896e-07, 3.1819e-05, 3.7967e-07, 9.9996e-01, 1.4092e-06,\n",
      "          6.8024e-06, 3.0870e-06, 2.5901e-08, 0.0000e+00],\n",
      "         [6.0162e-07, 4.6516e-08, 1.4382e-07, 8.5278e-08, 1.0000e+00,\n",
      "          3.7904e-09, 6.1095e-07, 9.3181e-10, 0.0000e+00],\n",
      "         [2.3922e-08, 3.1835e-07, 8.3451e-10, 5.6153e-08, 5.1705e-10,\n",
      "          1.0000e+00, 5.3872e-08, 1.4286e-10, 0.0000e+00],\n",
      "         [2.7354e-06, 3.1607e-05, 6.3413e-08, 1.8160e-06, 5.9390e-06,\n",
      "          3.8391e-06, 9.9995e-01, 2.3924e-08, 0.0000e+00],\n",
      "         [2.4714e-06, 6.8031e-07, 5.7869e-06, 3.0692e-07, 1.8246e-07,\n",
      "          2.0507e-07, 4.8190e-07, 9.9999e-01, 0.0000e+00],\n",
      "         [3.6731e-01, 3.0941e-01, 2.8317e-01, 4.9630e-03, 2.6265e-02,\n",
      "          3.0650e-04, 8.3993e-03, 1.7405e-04, 0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 5.4959e-07, 8.3991e-07, 1.3391e-08, 1.5518e-08,\n",
      "          2.5306e-08, 9.8387e-09, 2.3366e-08, 2.7097e-09],\n",
      "         [2.1150e-09, 1.0000e+00, 2.4197e-08, 6.5220e-10, 9.2097e-11,\n",
      "          5.0341e-11, 6.3011e-11, 7.7923e-10, 6.8053e-12],\n",
      "         [9.6678e-08, 7.2375e-07, 1.0000e+00, 7.4951e-08, 8.8016e-08,\n",
      "          1.8076e-08, 1.7304e-09, 3.1065e-08, 3.4680e-09],\n",
      "         [2.8973e-10, 3.6669e-09, 1.4089e-08, 1.0000e+00, 1.8472e-09,\n",
      "          9.5700e-10, 5.9884e-10, 7.9925e-11, 4.8725e-11],\n",
      "         [5.3437e-08, 8.2407e-08, 2.6330e-06, 2.9398e-07, 9.9999e-01,\n",
      "          6.7036e-06, 3.7666e-06, 1.0152e-06, 7.1796e-09],\n",
      "         [4.9220e-08, 2.5443e-08, 3.0544e-07, 8.6028e-08, 3.7865e-06,\n",
      "          1.0000e+00, 1.3881e-07, 2.7560e-07, 6.4967e-09],\n",
      "         [3.9691e-10, 6.6053e-10, 6.0647e-10, 1.1165e-09, 4.4127e-08,\n",
      "          2.8790e-09, 1.0000e+00, 4.0702e-08, 1.0467e-10],\n",
      "         [1.0250e-07, 8.8823e-07, 1.1839e-06, 1.6204e-08, 1.2933e-06,\n",
      "          6.2157e-07, 4.4259e-06, 9.9999e-01, 2.1886e-08],\n",
      "         [3.2761e-07, 2.1380e-07, 3.6427e-06, 2.7226e-07, 2.5208e-07,\n",
      "          4.0383e-07, 3.1368e-07, 6.0319e-07, 9.9999e-01]]],\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 4. Softmax\n",
    "attn_prob = nn.Softmax(dim=-1)(scores)\n",
    "print(attn_prob.size())\n",
    "print(attn_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acknowledged-identification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 128])\n"
     ]
    }
   ],
   "source": [
    "# 5. Matmul\n",
    "context = torch.matmul(attn_prob, V)\n",
    "print(context.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-senior",
   "metadata": {},
   "source": [
    "위의 과정들을 하나의 class로 바꾸어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "experienced-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.scale = 1 / (d_head ** 0.5)\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
    "        scores.masked_fill_(attn_mask, -1e9)\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
    "        # (bs, n_head, n_q_seq, d_v)\n",
    "        context = torch.matmul(attn_prob, V)\n",
    "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
    "        return context, attn_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-transmission",
   "metadata": {},
   "source": [
    "### 4. Multi-head attention\n",
    "\n",
    "<img src='../imgs/multi_head_attn.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-cookie",
   "metadata": {},
   "source": [
    "> multi-head attention을 사용하는 이유는 무엇일까????????????????????\n",
    "\n",
    "> Linear를 하는 이유는???? activation을 하는 것도 아닌데???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "solved-rings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "Q = inputs_pos_embed\n",
    "K = inputs_pos_embed\n",
    "V = inputs_pos_embed\n",
    "attn_mask = inputs.eq(0).unsqueeze(1).expand(Q.size(0), Q.size(1), K.size(1))\n",
    "\n",
    "batch_size = Q.size(0)\n",
    "num_heads = 2\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-protocol",
   "metadata": {},
   "source": [
    "> batch_size = Q.size(0)???? 문장의 개수?????\n",
    "\n",
    "> num_heads = 2인 이유는 dim_head = 64로 embedding size = 128을 나누어서?  >> YES\n",
    "\n",
    "> 그렇다면, 단순히 한번에 계산할 수 있는 것을 두 번으로 나누어서 계산??? 하는 이유는???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "tough-charger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 128]) torch.Size([2, 9, 128])\n",
      "torch.Size([2, 9, 2, 64])\n",
      "torch.Size([2, 2, 9, 64])\n"
     ]
    }
   ],
   "source": [
    "# 1, 2, 3. Q, K, V를 여러 개의 head로 나눈다.\n",
    "W_Q = nn.Linear(dim_hidn, num_heads * dim_head)\n",
    "W_K = nn.Linear(dim_hidn, num_heads * dim_head)\n",
    "W_V = nn.Linear(dim_hidn, num_heads * dim_head)\n",
    "\n",
    "# (bs, n_seq, n_head * d_head)\n",
    "q_s = W_Q(Q)\n",
    "print(Q.size(), q_s.size())\n",
    "# (bs, n_seq, n_head, d_head)\n",
    "q_s = q_s.view(batch_size, -1, num_heads, dim_head)\n",
    "print(q_s.size())\n",
    "# (bs, n_head, n_seq, d_head)\n",
    "q_s = q_s.transpose(1,2)\n",
    "print(q_s.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-lincoln",
   "metadata": {},
   "source": [
    "이를 한 줄로 표현하면, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "satisfied-warren",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 9, 64]) torch.Size([2, 2, 9, 64]) torch.Size([2, 2, 9, 64])\n"
     ]
    }
   ],
   "source": [
    "# (bs, n_head, n_seq, d_head)\n",
    "q_s = W_Q(Q).view(batch_size, -1, num_heads, dim_head).transpose(1,2)\n",
    "# (bs, n_head, n_seq, d_head)\n",
    "k_s = W_K(K).view(batch_size, -1, num_heads, dim_head).transpose(1,2)\n",
    "# (bs, n_head, n_seq, d_head)\n",
    "v_s = W_V(V).view(batch_size, -1, num_heads, dim_head).transpose(1,2)\n",
    "print(q_s.size(), k_s.size(), v_s.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "overall-quebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 9])\n",
      "torch.Size([2, 2, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "print(attn_mask.size())\n",
    "attn_mask = attn_mask.unsqueeze(1).repeat(1, num_heads, 1, 1)\n",
    "print(attn_mask.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "voluntary-cleaners",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 9, 64])\n",
      "torch.Size([2, 2, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "# 4. attention\n",
    "scaled_dot_attn = ScaledDotProductAttention(dim_head)\n",
    "context, attn_prob = scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
    "print(context.size())\n",
    "print(attn_prob.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "amino-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 128])\n"
     ]
    }
   ],
   "source": [
    "# 5. concat\n",
    "# (bs, n_seq, n_head * d_head)\n",
    "context = context.transpose(1, 2).contiguous().view(\\\n",
    "                        batch_size, -1, num_heads * dim_head)\n",
    "print(context.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afraid-adjustment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 128])\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(num_heads * dim_head, dim_hidn)\n",
    "# (bs, n_seq, d_hidn)\n",
    "output = linear(context)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-professional",
   "metadata": {},
   "source": [
    "위으 모든 과정을 하나의 class로 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "placed-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" multi head attention \"\"\"\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_hidn, n_head, d_head):\n",
    "        super().__init__()\n",
    "        self.d_hidn = d_hidn\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_head\n",
    "\n",
    "        self.W_Q = nn.Linear(d_hidn, n_head * d_head)\n",
    "        self.W_K = nn.Linear(d_hidn, n_head * d_head)\n",
    "        self.W_V = nn.Linear(d_hidn, n_head * d_head)\n",
    "        self.scaled_dot_attn = ScaledDotProductAttention(d_head)\n",
    "        self.linear = nn.Linear(n_head * d_head, d_hidn)\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        batch_size = Q.size(0)\n",
    "        # (bs, n_head, n_q_seq, d_head)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)\n",
    "        # (bs, n_head, n_k_seq, d_head)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)\n",
    "        # (bs, n_head, n_v_seq, d_head)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)\n",
    "\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_head, 1, 1)\n",
    "\n",
    "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
    "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_head * self.d_head)\n",
    "        # (bs, n_head, n_q_seq, e_embd)\n",
    "        output = self.linear(context)\n",
    "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        return output, attn_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-eclipse",
   "metadata": {},
   "source": [
    "### 5. Masked multi-head attention\n",
    "\n",
    "Masked Multi-Head Attention은 Multi-Head Attention과 attention mask를 제외한 부분은 모두 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "unexpected-weekly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False]])\n",
      "tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" attention decoder mask \"\"\"\n",
    "def get_attn_decoder_mask(seq):\n",
    "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
    "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
    "    return subsequent_mask\n",
    "\n",
    "\n",
    "Q = inputs_pos_embed\n",
    "K = inputs_pos_embed\n",
    "V = inputs_pos_embed\n",
    "\n",
    "attn_pad_mask = inputs.eq(0).unsqueeze(1).expand(Q.size(0), Q.size(1), K.size(1))\n",
    "print(attn_pad_mask[1])\n",
    "attn_dec_mask = get_attn_decoder_mask(inputs)\n",
    "print(attn_dec_mask[1])\n",
    "attn_mask = torch.gt((attn_pad_mask + attn_dec_mask), 0)\n",
    "print(attn_mask[1])\n",
    "\n",
    "batch_size = Q.size(0)\n",
    "n_head = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "sophisticated-practitioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 128]) torch.Size([2, 2, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "attention = MultiHeadAttention(dim_hidn, num_heads, dim_head)\n",
    "output, attn_prob = attention(Q, K, V, attn_mask)\n",
    "print(output.size(), attn_prob.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-eating",
   "metadata": {},
   "source": [
    "## FeedForwad\n",
    "\n",
    "<img src='../imgs/feedforward.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "destroyed-rouge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 9])\n"
     ]
    }
   ],
   "source": [
    "# 1. f_1\n",
    "conv1 = nn.Conv1d(in_channels=dim_hidn, \\\n",
    "                  out_channels=dim_hidn*4, kernel_size=1)\n",
    "# (bs, d_hidn * 4, n_seq)\n",
    "f_1 = conv1(output.transpose(1, 2))\n",
    "print(f_1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "binding-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. f_2: activation\n",
    "# active = F.relu\n",
    "acitvn = F.gelu\n",
    "f_2 = acitvn(f_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "blond-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 128])\n"
     ]
    }
   ],
   "source": [
    "# 3. f_3\n",
    "conv2 = nn.Conv1d(in_channels=dim_hidn * 4, \\\n",
    "                  out_channels=dim_hidn, kernel_size=1)\n",
    "f_3 = conv2(f_2).transpose(1, 2)\n",
    "print(f_3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "english-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" feed forward \"\"\"\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_hidn):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, \\\n",
    "                               out_channels=self.config.d_hidn*4,\\\n",
    "                               kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.config.d_hidn*4,\\\n",
    "                               out_channels=self.config.d_hidn,\\\n",
    "                               kernel_size=1)\n",
    "        self.activn = F.gelu\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # (bs, d_ff, n_seq)\n",
    "        output = self.activn(self.conv1(inputs.transpose(1, 2)))\n",
    "        # (bs, n_seq, d_hidn)\n",
    "        output = self.conv2(output).transpose(1, 2)\n",
    "        # (bs, n_seq, d_hidn)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "editorial-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" encoder \"\"\"\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
    "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_enc_seq + 1, self.config.d_hidn))\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
    "        pos_mask = inputs.eq(self.config.i_pad)\n",
    "        positions.masked_fill_(pos_mask, 0)\n",
    "\n",
    "        # (bs, n_enc_seq, d_hidn)\n",
    "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)\n",
    "\n",
    "        # (bs, n_enc_seq, n_enc_seq)\n",
    "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
    "\n",
    "        attn_probs = []\n",
    "        for layer in self.layers:\n",
    "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
    "            outputs, attn_prob = layer(outputs, attn_mask)\n",
    "            attn_probs.append(attn_prob)\n",
    "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        return outputs, attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "naval-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" decoder layer \"\"\"\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "        self.dec_enc_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
    "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "    \n",
    "    def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n",
    "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
    "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
    "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
    "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_enc_seq)\n",
    "        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n",
    "        # (bs, n_dec_seq, d_hidn)\n",
    "        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n",
    "        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n",
    "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
    "        return ffn_outputs, self_attn_prob, dec_enc_attn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "hollow-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" decoder \"\"\"\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
    "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
    "    \n",
    "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
    "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
    "        positions.masked_fill_(pos_mask, 0)\n",
    "    \n",
    "        # (bs, n_dec_seq, d_hidn)\n",
    "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
    "\n",
    "        # (bs, n_dec_seq, n_dec_seq)\n",
    "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
    "        # (bs, n_dec_seq, n_dec_seq)\n",
    "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
    "        # (bs, n_dec_seq, n_dec_seq)\n",
    "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
    "        # (bs, n_dec_seq, n_enc_seq)\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n",
    "\n",
    "        self_attn_probs, dec_enc_attn_probs = [], []\n",
    "        for layer in self.layers:\n",
    "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, n_dec_seq, n_enc_seq)\n",
    "            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            self_attn_probs.append(self_attn_prob)\n",
    "            dec_enc_attn_probs.append(dec_enc_attn_prob)\n",
    "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)], [(bs, n_dec_seq, n_enc_seq)]S\n",
    "        return dec_outputs, self_attn_probs, dec_enc_attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "detailed-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" transformer \"\"\"\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.encoder = Encoder(self.config)\n",
    "        self.decoder = Decoder(self.config)\n",
    "    \n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)\n",
    "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
    "        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
    "        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-homework",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
